{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nucliadb_sdk import NucliaDB, Region\n",
    "\n",
    "sdk = NucliaDB(api_key=\"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6InNhIn0.eyJpc3MiOiJodHRwczovL251Y2xpYS5jbG91ZC8iLCJpYXQiOjE2OTUyMjE1MDEsInN1YiI6ImQ1N2Y0Y2U0LWFhYzUtNDIxZS05MmY2LTY2ZDE3YzdlNWVkMiIsImp0aSI6IjljZTgzODNmLTkxY2QtNGJhZS1iMTEzLTAzMzJlOWQwYTFjNiIsImV4cCI6MTcyNjg0MzkwMSwia2V5IjoiODc1MzkzMjEtNDJhNi00YzdlLTk0MmQtY2E2YjI2NmE0MGJiIiwia2lkIjoiZDE3OTI1N2EtM2NjZC00MjJiLWIyZGUtOGRhYWZlOWRhNTljIn0.hQInGFN0kRvdOSWQMNlS9DCXULgmDUXjkFHzQn4QKWiba4EhneWXfhnoqaquukBaCoAGGwKSbDK7mKcN-Fh-KbTxVTfcqElQ8tHEAUroA51Fk8iHDLT5rTUc2C-cf06ciCKT5_mdahq2ToUuCi0Lzi79gWVrnxLkEFr_Qvm9TzhNkhH5uRmFIA-P6D9-YVbIuS4andpTG2N5pkMQx8nZBpd3T9WNOjyNb1DgBi1DeBMAOPG9cguTAgKofNisY5Uj0GnqXtJ0BFQEd1jO7lwDCPEDjspDBPNaX58xg3Qy5kfNkdPi14XacJi-Dy-4cpH6eavRwVcvdLLzTuY1TPhSuUmsTz-6-QEONvfK_xCydYPAj8slqSIRhel_gUzJvEZGqUe9jIAfrzBm6k0LQ0-QRo-HbbLm-ynQlqtcsoFupk9BPEPrXvUlug9OlYHah89We1TAnCf1OrVTtYo0G2VyE9ctVUf2EtTh_WFioAyEuydIgHFSYROJMvXYBmE3MbM5vAncjBZvSPKJBo_swTmuzXGKWOEHs4G__ecCW6V1WBwCKbDoZQDto2yfCE7PTnwYM2HzOmPj4ZDX7LKg8mA1kF30J9VlRiu1cWmXPOZmz-hOBCrokWZPJqUOhkZrnM8_uvoOteCuB_DmETpZqkh2ZeiJcCUgDw1wjNT5EhsJ9XM\", region=Region.ON_PREM, url=\"http://localhost:8080/api\")\n",
    "\n",
    "kb = sdk.create_knowledge_box(slug=\"writingassisstant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/omar/4CC8FF56C8FF3D30/AsasLab/asas-writer-assistant/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)21fe2/.gitattributes: 100%|██████████| 502/502 [00:00<00:00, 5.66MB/s]\n",
      "Downloading (…)de57421fe2/README.md: 100%|██████████| 8.26k/8.26k [00:00<00:00, 33.3MB/s]\n",
      "Downloading (…)57421fe2/config.json: 100%|██████████| 385/385 [00:00<00:00, 4.11MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 1.48G/1.48G [01:02<00:00, 23.7MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.48G/1.48G [00:59<00:00, 24.7MB/s]\n",
      "Downloading (…)608671820.tpu-mother: 100%|██████████| 5.14M/5.14M [00:00<00:00, 7.16MB/s]\n",
      "Downloading (…)608673456.tpu-mother: 100%|██████████| 5.14M/5.14M [00:00<00:00, 7.08MB/s]\n",
      "Downloading (…)608680655.tpu-mother: 100%|██████████| 5.14M/5.14M [00:00<00:00, 7.20MB/s]\n",
      "Downloading (…)uns/eval_results.txt: 100%|██████████| 166/166 [00:00<00:00, 1.42MB/s]\n",
      "Downloading (…)605874563.tpu-mother: 100%|██████████| 12.3M/12.3M [00:00<00:00, 12.5MB/s]\n",
      "Downloading (…)605874678.tpu-mother: 100%|██████████| 52.6M/52.6M [00:02<00:00, 19.4MB/s]\n",
      "Downloading (…)605961833.tpu-mother: 100%|██████████| 52.6M/52.6M [00:02<00:00, 21.1MB/s]\n",
      "Downloading (…)605973475.tpu-mother: 100%|██████████| 52.6M/52.6M [00:02<00:00, 21.1MB/s]\n",
      "Downloading (…)605978079.tpu-mother: 100%|██████████| 52.6M/52.6M [00:02<00:00, 19.0MB/s]\n",
      "Downloading (…)605988172.tpu-mother: 100%|██████████| 52.6M/52.6M [00:02<00:00, 19.7MB/s]\n",
      "Downloading (…)605990305.tpu-mother: 100%|██████████| 52.6M/52.6M [00:03<00:00, 16.6MB/s]\n",
      "Downloading (…)606004975.tpu-mother: 100%|██████████| 52.6M/52.6M [00:03<00:00, 15.8MB/s]\n",
      "Downloading (…)606049924.tpu-mother: 100%|██████████| 52.6M/52.6M [00:02<00:00, 21.6MB/s]\n",
      "Downloading (…)606136686.tpu-mother: 100%|██████████| 52.6M/52.6M [00:02<00:00, 20.8MB/s]\n",
      "Downloading (…)606215927.tpu-mother: 100%|██████████| 12.3M/12.3M [00:14<00:00, 862kB/s]\n",
      "Downloading (…)606216242.tpu-mother: 100%|██████████| 52.7M/52.7M [00:02<00:00, 21.1MB/s]\n",
      "Downloading (…)606303030.tpu-mother: 100%|██████████| 12.3M/12.3M [00:01<00:00, 11.7MB/s]\n",
      "Downloading (…)606308244.tpu-mother: 100%|██████████| 12.3M/12.3M [00:00<00:00, 12.7MB/s]\n",
      "Downloading (…)606315473.tpu-mother: 100%|██████████| 12.3M/12.3M [00:00<00:00, 12.9MB/s]\n",
      "Downloading (…)606333742.tpu-mother: 100%|██████████| 52.7M/52.7M [00:02<00:00, 21.7MB/s]\n",
      "Downloading (…)606372367.tpu-mother: 100%|██████████| 12.3M/12.3M [00:00<00:00, 12.4MB/s]\n",
      "Downloading (…)606396579.tpu-mother: 100%|██████████| 52.7M/52.7M [00:02<00:00, 21.8MB/s]\n",
      "Downloading (…)606425736.tpu-mother: 100%|██████████| 12.3M/12.3M [00:00<00:00, 12.6MB/s]\n",
      "Downloading (…)606429325.tpu-mother: 100%|██████████| 52.7M/52.7M [00:02<00:00, 19.1MB/s]\n",
      "Downloading (…)606448505.tpu-mother: 100%|██████████| 52.7M/52.7M [00:02<00:00, 19.6MB/s]\n",
      "Downloading (…)606492226.tpu-mother: 100%|██████████| 52.7M/52.7M [00:02<00:00, 20.9MB/s]\n",
      "Downloading (…)606522644.tpu-mother: 100%|██████████| 52.7M/52.7M [00:02<00:00, 21.0MB/s]\n",
      "Downloading (…)606530340.tpu-mother: 100%|██████████| 52.7M/52.7M [00:02<00:00, 20.7MB/s]\n",
      "Downloading (…)606617727.tpu-mother: 100%|██████████| 52.7M/52.7M [00:02<00:00, 21.5MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 1.07MB/s]\n",
      "Downloading tf1_model.tar.gz: 100%|██████████| 1.38G/1.38G [00:55<00:00, 24.7MB/s]\n",
      "Downloading (…)21fe2/tokenizer.json: 100%|██████████| 2.64M/2.64M [00:00<00:00, 4.83MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 382/382 [00:00<00:00, 4.58MB/s]\n",
      "Downloading (…)de57421fe2/vocab.txt: 100%|██████████| 825k/825k [00:00<00:00, 31.4MB/s]\n",
      "No sentence-transformers model found with name /home/omar/.cache/torch/sentence_transformers/aubmindlab_bert-large-arabertv02. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from nucliadb_sdk.client import Environment\n",
    "from nucliadb_sdk import KnowledgeBox\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder = SentenceTransformer('aubmindlab/bert-large-arabertv02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorset is not created, we will create it for you\n"
     ]
    }
   ],
   "source": [
    "from nucliadb_sdk import create_knowledge_box, delete_kb\n",
    "documents = [\"هذا نص بسيط للتجربة\", \"السلام عليكم ورحمة الله وبركاته\", \"مرحبا بكم في العالم العربي\"]\n",
    "\n",
    "vectorset_name = 'arabertv02'\n",
    "my_kb = create_knowledge_box('testkb')\n",
    "for i in range(0, len(documents)):\n",
    "    document = documents[i]\n",
    "    vectors = encoder.encode([document])\n",
    "    resource_id = my_kb.upload(\n",
    "        key = 'mykey' + str(i),\n",
    "        text=document,\n",
    "        labels = ['progs/things'],\n",
    "        vectors={vectorset_name: vectors[0]},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorset_name = 'arabertv02'\n",
    "search_str = 'السلام عليكم'\n",
    "query_vector = encoder.encode([search_str])\n",
    "results = my_kb.search(\n",
    "    vector= query_vector[0],\n",
    "    filter=['progs/things'],\n",
    "    vectorset=vectorset_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    print(f'Text: {result.text} - Score: {result.score} - Labels: {result.labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
